{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5719aa95-cb38-4085-bf6f-44efe74a046f",
   "metadata": {},
   "source": [
    "## Greenburgh Tax Assessment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae71eca6-7ac8-4530-b179-8c81f10ba242",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ef26a-686a-4453-b7d8-0500bc17a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## It is important that the tax_utils.py file (in src/utils) is accessible by your\n",
    "## PYHTHONPATH environment variable.\n",
    "## NOTE: If tax_utils.py is changed it will need to byte compiled before it can be used \n",
    "##       in this notebook.\n",
    "##       To do this do the following:\n",
    "##       cd src/utils\n",
    "##       python -m py_compile tax_utils.py\n",
    "import tax_utils as utils\n",
    "\n",
    "## If you have support for jax, you can import of tax_utils with the following line.\n",
    "#import tax_jax_utils as utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import sqlite3 as lite\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c54f4-1830-438e-98b1-93059643f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tax assessment database and Assessment table.\n",
    "TAX_ASSESS_DB = \"/home/rsm/proj/tax_ass/taxdb/taxrec.db\"\n",
    "ASSESS_TABLE='taxrec'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecadbad0-ebdf-43a1-9db7-8841162a1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to database and read in data from table, <ASSESS_TABLE>.\n",
    "conn  = lite.connect(TAX_ASSESS_DB)\n",
    "query = f\"SELECT * from {ASSESS_TABLE};\"\n",
    "df    = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418f0336-2c43-44b1-8ae3-0a6d92227c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We need data sorted by year as we will group by YEAR to get a list of FULL_MKT_VALUE(s)\n",
    "## which we will use to create a return series, and placed in a field in <df>.\n",
    "df = df.sort_values(by='YEAR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd65802-690f-4400-82e9-42b907322a9f",
   "metadata": {},
   "source": [
    "### Data Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f297fba-f92c-47ba-9424-f00d4db42222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c858d-66ac-4394-a19f-32e7ebb818c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.PARCEL_TYPE.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006193a7-ce1b-47d1-b3a9-d7310f8336f8",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "We use regular expression matching to determine which data should be filtered out.\n",
    "We create a dictionary below, badLinesDct, that contains the number of bad lines\n",
    "for each field of interest: FULL_MKT_VALUE (market value of parcel), ACCT (parcel account id), LUC (Land Use Code), ACCR (parcel acreage size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d9cddc-2701-4e28-b403-602f3989e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "badLinesDct = {}\n",
    "good_mkt_filter = df[\"FULL_MKT_VALUE\"].astype(str).str.match(\"^\\d+$\")\n",
    "badLinesDct['FULL_MKT_VALUE']  = df.loc[~ good_mkt_filter].shape[0]\n",
    "\n",
    "good_acct_filter = df[\"ACCT\"].astype(str).str.match(\"^\\d+$\")\n",
    "badLinesDct['ACCT'] = df.loc[~ good_acct_filter].shape[0]\n",
    "\n",
    "good_luc_filter = df['LUC'].astype(str).str.match(\"^\\d+$\")\n",
    "badLinesDct['LUC'] = df.loc[~ good_luc_filter].shape[0]\n",
    "\n",
    "good_accr_filter = df['ACCR'].astype(str).str.match(\"(^(\\d*)\\.\\d+$)|(^\\d+(\\.\\d*)?$)\")\n",
    "badLinesDct['ACCR'] = df.loc[~ good_accr_filter].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb65df-6f9a-47ee-841f-d0a27ab454c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter out the bad mkt value, luc, and acct data.\n",
    "df_filt = df[(good_mkt_filter & good_luc_filter & good_acct_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec595b6-14c2-41dc-b89b-06b5bf725c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = df_filt.groupby('ACCT')['FULL_MKT_VALUE'].agg(lambda x: x.size).reset_index(name='MKT_COUNT')\n",
    "\n",
    "dd1 = df_filt.groupby('ACCT')['FULL_MKT_VALUE'].agg(lambda x: any(x == 0)).reset_index(name='MKT_ZERO')\n",
    "\n",
    "ddd = dd.merge(dd1, on='ACCT', how='inner')\n",
    "\n",
    "## Now get the accounts that extend over the 11 period that we have data mkt value data for AND which aren't zero.\n",
    "accts = ddd.loc[(ddd.MKT_COUNT == 11) & (~ ddd.MKT_ZERO)].ACCT\n",
    "\n",
    "## Only use these accounts from the filtered data. This is the data set we will use for analysis.\n",
    "df_clean = df_filt.loc[df_filt['ACCT'].isin(accts), :]\n",
    "df_clean.to_csv(\"clean_tax_ass.psv\", sep='^', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7495f505-5f17-494c-b6a0-e7d42f0a375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Describe the reduction in data after cleaning.\n",
    "print(f\"Data cleaning reduced the overall data set by {100.0 * np.round( (df.shape[0] - df_clean.shape[0]) / df.shape[0], 2)}%.\")\n",
    "raw_residencial_count = df.loc[df.LUC == 210].shape[0]\n",
    "filtered_residencial_count = df_clean.loc[df_clean.LUC == 210].shape[0]\n",
    "print(f\"Data cleaning reduced the residencial data set by {100.0 * np.round( (raw_residencial_count - filtered_residencial_count) / raw_residencial_count, 2)}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80837409-a7c4-41ee-8558-c305785ff04a",
   "metadata": {},
   "source": [
    "### Compute Market Return Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd4e39-2477-48ca-9418-10ca073abef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a field, 'mkt_vals' that is an np.array of returns (ordered by YEAR).\n",
    "print(f\"Shape of df_clean = {df_clean.shape}\")\n",
    "df_rets = df_clean.groupby('ACCT').apply(lambda row: np.array(row['FULL_MKT_VALUE'])).reset_index(name='mkt_vals')\n",
    "print(f\"Shape of df_rets = {df_rets.shape}\")\n",
    "df_rets['mkt_rets'] = df_rets['mkt_vals'].apply(lambda x: np.diff(x)) / df_rets['mkt_vals'].apply(lambda x: x[:-1])\n",
    "\n",
    "df_rets['avg_mkt_val'] = df_rets.apply(lambda row: np.mean(row['mkt_vals']), axis=1)\n",
    "\n",
    "df_rets = df_clean.merge(df_rets, on='ACCT', how='inner')\n",
    "print(f\"Shape of df_rets = {df_rets.shape}\")\n",
    "\n",
    "## Pick the first year of the data, we have all of the return and market values for all years stored as vectors.\n",
    "## So, the fields for most things don't change over the years; however, OWN1 and OWN2 can most likely change.\n",
    "df_rets = df_rets.loc[df_rets.YEAR == df_rets.YEAR.unique().min(), :]\n",
    "\n",
    "print(f\"Shape of df_rets = {df_rets.shape}\")\n",
    "df_rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a196427-9c4f-4ec3-849f-e05c05e850f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.value_counts(df_rets.LUC).to_frame(name='LUC_cnt').reset_index()\n",
    "dff['log_LUC'] = np.log10(dff.LUC_cnt)\n",
    "ax = dff.plot.scatter(x = 'LUC', y='log_LUC', xlabel='LUC\\n(Residencial LUC=210)', ylabel='Log10 of LUC Count', title=\"Log10 of LUC counts\")\n",
    "ax.axvline(210, linestyle='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d6dfe7-9f67-4bdb-b5c5-cd7669f338d2",
   "metadata": {},
   "source": [
    "### Aggregate Market Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1b03c-88b7-4b66-b80a-f15b8e780671",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Empty data frame to store returns.\n",
    "df_results = pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf1684-ebdd-4581-99a7-78ffdbdfb3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Overall Aggregated Market Returns\n",
    "df_results['overall'] = df_rets['mkt_rets'].agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c353cea-35db-4613-87cc-4cee74d4834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregated Market Returns for LUC 210 -- Single family residence.\n",
    "df_results['residence'] = df_rets.loc[df_rets['LUC'] == 210, 'mkt_rets'].agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca9558-8251-4a61-a749-a170e03e0f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute overall weighted returns using the average market value as the weight \n",
    "## -- Also recompute but restrict analysis to single family residences -- LUC = 210.\n",
    "df_results['overall_mkt_wgt']       = utils.assessment_agr_rets(df_rets, 'mkt_rets', 'avg_mkt_val')\n",
    "df_results['residence_mkt_wgt']     = utils.assessment_agr_rets(df_rets, 'mkt_rets', 'avg_mkt_val', filt = df_rets['LUC'] == 210)\n",
    "df_results['overall_mkt_wgt_med']   = utils.assessment_wgt_quant_rets(df_rets, 'mkt_rets', 'avg_mkt_val', np.array([0.5]))[:, 0] \n",
    "df_results['residence_mkt_wgt_med'] = utils.assessment_wgt_quant_rets(df_rets, 'mkt_rets', 'avg_mkt_val', np.array([0.5]), filt=df_rets['LUC'] == 210)[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82b8e4-f06a-4578-a2c8-0365fae5e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_results[['residence', 'overall_mkt_wgt', 'overall_mkt_wgt_med', 'residence_mkt_wgt', 'residence_mkt_wgt_med']].plot( \n",
    "                     xlabel=\"Year\"                     , \n",
    "                     ylabel=\"Assessment Change from Previous Year\",\n",
    "                     title=\"Tax Assessment Comparison (Greenburgh)\" ,\n",
    "                     xticks=df_results.index, rot=90    )\n",
    "ax.set_xticklabels(['2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']);\n",
    "ax.legend(['Residential Avg', 'Overall Mkt Wgt Avg', 'Overall Mkt Wgt Med', 'Residential Mkt Wgt Avg', 'Residential Mkt Wgt Med']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55430804-5956-4761-b8ef-62b5483ec132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Compute various cumulative weighted returns.\n",
    "\n",
    "## Overall Aggregated (Avg) Market cumulative Returns\n",
    "df_results['overall_cs'] = np.cumprod(1.0 + df_rets['mkt_rets'].agg(np.mean)) - 1.0\n",
    "\n",
    "## Residential Aggregated (Avg) Market Cumulative Returns for LUC 210 -- Single family residence.\n",
    "df_results['residence_cs'] = np.cumprod(1.0 + df_rets.loc[df_rets['LUC'] == 210, 'mkt_rets'].agg(np.mean)) - 1.0\n",
    "\n",
    "## Repeat the above with Aggregated (Avg and Med) weighted returns using the average market value as the weight.\n",
    "df_results['overall_mkt_wgt_cs'] = np.cumprod(1.0 + utils.assessment_agr_rets(df_rets, 'mkt_rets', 'avg_mkt_val')) - 1.0\n",
    "df_results['overall_mkt_med_cs'] = np.cumprod(1.0 + utils.assessment_wgt_quant_rets(df_rets, 'mkt_rets', 'avg_mkt_val', np.array([0.5]))[:, 0]) - 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad47533-97ab-420a-afcf-9448c1d6ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute overall weighted returns using the average market value as the weight \n",
    "## -- but restrict analysis to single family residences -- LUC = 210.\n",
    "df_results['residence_mkt_wgt_cs'] = np.cumprod(1.0 + utils.assessment_agr_rets(df_rets, 'mkt_rets', 'avg_mkt_val', filt = df_rets['LUC'] == 210)) - 1.0\n",
    "df_results['residence_mkt_med_cs'] = np.cumprod(1.0 + utils.assessment_wgt_quant_rets(df_rets, 'mkt_rets', 'avg_mkt_val', np.array([0.5]), filt=df_rets['LUC'] == 210)[:, 0]) - 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fa8da-60a0-453a-a979-e5a3fb08e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_results[['residence_cs', 'overall_mkt_wgt_cs', 'overall_mkt_med_cs', 'residence_mkt_wgt_cs', 'residence_mkt_med_cs']].plot( \n",
    "                     xlabel=\"Year\"                     , \n",
    "                     ylabel=\"Assessment Change from 2012\",\n",
    "                     title=\"Tax Assessment Comparison (Greenburgh)\\n(Cumulative Change)\" ,\n",
    "                     xticks=df_results.index, rot=90    )\n",
    "ax.set_xticklabels(['2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022']);\n",
    "ax.legend(['Residential Avg', 'Overall Mkt Wgt Avg', 'Overall Mkt Med', 'Residential Mkt Wgt Avg', 'Residential Mkt Med']);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
